{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Navie - CNN\n",
    "\n",
    "\n",
    "- This is a four layers Navie-CNN demo. \n",
    "- Training on CIFAR10, define a dataset transformation function which contains Decrete Fourier Transform function.\n",
    "- But the applied path of DFT haven'd conformed yet, which will be discussed in later paper work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Run bunch of settings\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms # Provide common datasets and transformation function.\n",
    "print(\"PyTorch Version: \",torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classical CNN model\n",
    "# The input of model is 5000 * 3 * 32 * 32 and label's vector is 5000 * 1\n",
    "# Each image's scale is 3 * 32 * 32\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Conv2d(depth, num_init_features, kernel_size, stride, padding, bias=False)\n",
    "        # nn.Linear(num_input, num_output)\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 1, 1)      # (32 - 1 + 0) / 1 + 1 = 32\n",
    "        self.conv2 = nn.Conv2d(64, 128, 4, 1, 3) # (32 - 4 + 3) / 1 + 1 = 32 \n",
    "        self.conv3 = nn.Conv2d(128, 256, 5, 1)   # (32 - 5 + 0) / 1 + 1 = 28 -> 20 * 28 * 28\n",
    "        self.conv4 = nn.Conv2d(256, 256, 5, 1)   # (28 - 5 + 0) / 1 + 1 = 24 -> 50 * 20 * 20\n",
    "        self.fc1 = nn.Linear(5*5*256, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):     #x: #   1 *  32  *  32 \n",
    "        x = F.relu(self.conv1(x)) #  64 *  32  *  32\n",
    "        x = F.max_pool2d(x,2,1)   #  64 *  32  *  32\n",
    "        x = F.relu(self.conv2(x)) # 128 *  32  *  32\n",
    "        x = F.max_pool2d(x,2,1)   # 128 *  32  *  32\n",
    "        x = F.relu(self.conv3(x)) #  20 *  28  *  28\n",
    "        x = F.max_pool2d(x,2,2)   #  20 *  14  *  14\n",
    "        x = F.relu(self.conv4(x)) #  50 *  10  *  10\n",
    "        x = F.max_pool2d(x,2,2)   #  50 *   5  *   5\n",
    "        x = x.view(-1, 5*5*256)    # reshape (5 * 2 * 10), view(5, 20) -> (5 * 20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #return x\n",
    "        return F.log_softmax(x, dim=1) # log probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defin the train function \n",
    "# input : model, device, train_loader, optimizer, num_epoch\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        pred = model(data) # batch_size * classes -> 5 * 10 \n",
    "        loss = F.cross_entropy(pred, target) + F.nll_loss(pred, target)  \n",
    "        \n",
    "        #print(\"pred.shape :{}\".format(pred.shape))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(\"Train Epoch: {}, iteration: {}, Loss: {}\".format(\n",
    "                epoch, idx, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defin the test function \n",
    "# input : model, device, test_loader\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    correct = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(test_dataloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            total_loss += F.nll_loss(output, target, reduction=\"sum\").item() \n",
    "            pred = output.argmax(dim=1) # batch_size  -> 5 \n",
    "            #print(\"pred.shape :{}\".format(pred.shape))\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            #print(\"idx :{} Correct :{}\".format(idx, correct))\n",
    "            \n",
    "    total_loss /= len(test_dataloader.dataset)    \n",
    "    acc = correct / len(test_dataloader.dataset) * 100.\n",
    "    print(\"Test loss:{}, Accuracy:{}\".format(total_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation function\n",
    "class ToArray(object):\n",
    "    def __call__(self, pic):\n",
    "        return np.array(pic)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation function\n",
    "class Fourier(object):\n",
    "    def __call__(self, pic):\n",
    "        x,y = 32, 32\n",
    "        cw = 6\n",
    "        # Normal Gaussion Filter\n",
    "        filter = np.ones((y,x))\n",
    "        filter[int(y/2 - cw):int(y/2 + cw), int(x/2 -cw):int(x/2 + cw)] = 0 \n",
    "        # Deceret Fourier Tranformation\n",
    "        fshift = np.fft.fftshift(np.fft.fft2(pic))\n",
    "        res1 = np.log(1 + np.abs(fshift)) \n",
    "        fshift *= filter      \n",
    "        res2 = np.log(1 + np.abs(fshift))    \n",
    "        iimg = np.fft.ifft2(np.fft.ifftshift(fshift))\n",
    "        iimg = np.abs(iimg)\n",
    "        a = np.ones((x, y, 3))\n",
    "        for i in range(3):\n",
    "            a[:,:,i] = iimg\n",
    "        a = np.maximum(0, a / np.max(a)).astype(np.float32)\n",
    "        return a\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_train :0.4733648896217346, std_train :0.25156906247138977.\n"
     ]
    }
   ],
   "source": [
    "# Extract mean and std of train data.\n",
    "data = [d[0].data.cpu().numpy() for d in data]\n",
    "avg_train = np.mean(data_train)\n",
    "std_train = np.std(data_train)\n",
    "print(\"avg_train :{}, std_train :{}.\".format(avg_train, std_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Training Device and dataloader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 5\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\"./CIFAR10_data\", train=True, download=True,\n",
    "                                    transform=transforms.Compose([transforms.Grayscale(), \n",
    "                                                                  Fourier(),\n",
    "                                                                  transforms.ToTensor(),\n",
    "                                                                  transforms.Normalize((0.4734,), (0.2516,))\n",
    "                                                                 ]))\n",
    "    , batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\"./CIFAR10_data\", train=False, download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.4734,), (0.2516,))\n",
    "                     ]))\n",
    "    , batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0, iteration: 0, Loss: 4.612001419067383\n",
      "Train Epoch: 0, iteration: 1000, Loss: 4.5965681076049805\n",
      "Train Epoch: 0, iteration: 2000, Loss: 4.628288269042969\n",
      "Train Epoch: 0, iteration: 3000, Loss: 4.459005832672119\n",
      "Train Epoch: 0, iteration: 4000, Loss: 4.6137495040893555\n",
      "Train Epoch: 0, iteration: 5000, Loss: 4.898815155029297\n",
      "Train Epoch: 0, iteration: 6000, Loss: 4.197612762451172\n",
      "Train Epoch: 0, iteration: 7000, Loss: 4.358684539794922\n",
      "Train Epoch: 0, iteration: 8000, Loss: 3.7393100261688232\n",
      "Train Epoch: 0, iteration: 9000, Loss: 3.9017131328582764\n",
      "Test loss:2.839319881296158, Accuracy:11.5\n",
      "Train Epoch: 1, iteration: 0, Loss: 4.358511924743652\n",
      "Train Epoch: 1, iteration: 1000, Loss: 4.090919494628906\n",
      "Train Epoch: 1, iteration: 2000, Loss: 4.677031993865967\n",
      "Train Epoch: 1, iteration: 3000, Loss: 3.9711737632751465\n",
      "Train Epoch: 1, iteration: 4000, Loss: 5.256221771240234\n",
      "Train Epoch: 1, iteration: 5000, Loss: 4.568746089935303\n",
      "Train Epoch: 1, iteration: 6000, Loss: 4.458547592163086\n",
      "Train Epoch: 1, iteration: 7000, Loss: 4.5907793045043945\n",
      "Train Epoch: 1, iteration: 8000, Loss: 4.790453910827637\n",
      "Train Epoch: 1, iteration: 9000, Loss: 3.9592843055725098\n",
      "Test loss:2.7802204941749573, Accuracy:11.49\n",
      "Train Epoch: 2, iteration: 0, Loss: 4.939922332763672\n",
      "Train Epoch: 2, iteration: 1000, Loss: 4.4687018394470215\n",
      "Train Epoch: 2, iteration: 2000, Loss: 3.741877317428589\n",
      "Train Epoch: 2, iteration: 3000, Loss: 4.8108015060424805\n",
      "Train Epoch: 2, iteration: 4000, Loss: 4.965607643127441\n",
      "Train Epoch: 2, iteration: 5000, Loss: 4.382033348083496\n",
      "Train Epoch: 2, iteration: 6000, Loss: 3.1609418392181396\n",
      "Train Epoch: 2, iteration: 7000, Loss: 3.1854681968688965\n",
      "Train Epoch: 2, iteration: 8000, Loss: 4.0124945640563965\n",
      "Train Epoch: 2, iteration: 9000, Loss: 3.5817995071411133\n",
      "Test loss:2.6815395276069642, Accuracy:14.44\n",
      "Train Epoch: 3, iteration: 0, Loss: 5.338468074798584\n",
      "Train Epoch: 3, iteration: 1000, Loss: 4.435772895812988\n",
      "Train Epoch: 3, iteration: 2000, Loss: 4.9143571853637695\n",
      "Train Epoch: 3, iteration: 3000, Loss: 4.355592727661133\n",
      "Train Epoch: 3, iteration: 4000, Loss: 3.4281699657440186\n",
      "Train Epoch: 3, iteration: 5000, Loss: 3.536482334136963\n",
      "Train Epoch: 3, iteration: 6000, Loss: 3.7731361389160156\n",
      "Train Epoch: 3, iteration: 7000, Loss: 3.6936988830566406\n",
      "Train Epoch: 3, iteration: 8000, Loss: 3.879784107208252\n",
      "Train Epoch: 3, iteration: 9000, Loss: 4.358843803405762\n",
      "Test loss:2.5260624540805816, Accuracy:14.790000000000001\n",
      "Train Epoch: 4, iteration: 0, Loss: 5.04046106338501\n",
      "Train Epoch: 4, iteration: 1000, Loss: 4.146900177001953\n",
      "Train Epoch: 4, iteration: 2000, Loss: 3.0683493614196777\n",
      "Train Epoch: 4, iteration: 3000, Loss: 5.103628158569336\n",
      "Train Epoch: 4, iteration: 4000, Loss: 3.7071876525878906\n",
      "Train Epoch: 4, iteration: 5000, Loss: 3.6324100494384766\n",
      "Train Epoch: 4, iteration: 6000, Loss: 4.402207851409912\n",
      "Train Epoch: 4, iteration: 7000, Loss: 4.153779983520508\n",
      "Train Epoch: 4, iteration: 8000, Loss: 3.9269981384277344\n",
      "Train Epoch: 4, iteration: 9000, Loss: 3.5758719444274902\n",
      "Test loss:2.4064010597229, Accuracy:13.719999999999999\n"
     ]
    }
   ],
   "source": [
    "# Training Procress\n",
    "lr = 1e-6\n",
    "momentum = 0.5\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, device, train_dataloader, optimizer, epoch)\n",
    "    test(model, device, test_dataloader)\n",
    "torch.save(model.state_dict(), \"CIFAR10_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
